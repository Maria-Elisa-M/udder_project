{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee42c445-45d5-4287-9b7c-2bf838c244d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marie\\AppData\\Local\\Temp\\ipykernel_18108\\3028730387.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import date, datetime, timedelta\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86416494-3629-4e12-ae87-c133cc7c69ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_seconds(interval_str):\n",
    "    if len(interval_str.split(\" d \")) > 1:\n",
    "        days = int(interval_str.split(\" d \")[0])\n",
    "        times = interval_str.split(\" d \")[1].split(\":\")\n",
    "    else:\n",
    "        days = 0\n",
    "        times = interval_str.split(\" d \")[-1].split(\":\")\n",
    "    hours = int(times[0])\n",
    "    minutes = int(times[1])\n",
    "    seconds = int(times[2])\n",
    "    interval = timedelta(days = days, hours = hours, minutes = minutes, seconds = seconds).total_seconds()\n",
    "    return interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a234a20-de42-404d-b00a-af7ca843a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_long(df, info_cols, col_dict):\n",
    "    for i, key in enumerate(col_dict.keys()):\n",
    "        sel_cols = info_cols + col_dict[key]\n",
    "        temp = df[sel_cols]\n",
    "        # select columns and melt \n",
    "        temp2 = pd.wide_to_long(temp, [key], i = info_cols, j=\"teat\", sep='_', suffix=r'\\w+').reset_index()\n",
    "        if i == 0:\n",
    "            df_long = temp2.copy()\n",
    "        else:\n",
    "            df_long = pd.merge(df_long, temp2, on = info_cols + [\"teat\"])\n",
    "    return df_long\n",
    "\n",
    "def get_col_dict(df, teat_list):\n",
    "    # find columns with teats\n",
    "    columns_q = [col for col in df.columns if col.split(\"_\")[-1] in teat_list]\n",
    "    col_dict = {}\n",
    "    for col in  columns_q:\n",
    "        key = \"_\".join(col.split(\"_\")[0:-1])\n",
    "        if key in col_dict.keys():\n",
    "            col_dict[key].append(col)\n",
    "        else:\n",
    "            col_dict[key] = [col]\n",
    "    return col_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e048566c-c7e4-4992-a47e-e771f817b246",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = os.getcwd()\n",
    "data_path = os.path.join(dirpath, \"..\", \"delpro_vms\", \"data\")\n",
    "feature_path = os.path.join(dirpath, \"..\", \"udder_processing\", \"features_dict\")\n",
    "out_dir = \"long_format_df\"\n",
    "# read vistit data\n",
    "visit_df = pd.read_csv(os.path.join(data_path, \"milk_videos_visit.csv\"))\n",
    "visit_df[\"interval_sec\"] = [interval_seconds(rec) for rec in visit_df.interval]\n",
    "visit_df = visit_df.drop_duplicates(subset='cow', keep=\"first\")\n",
    "# read features\n",
    "feature_df = pd.read_csv(os.path.join(feature_path, \"gmfeature_table.csv\"))\n",
    "feature_df = feature_df.rename(columns = lambda col: \"_\".join(col.split(\"_\")[::-1]) if \"_\" in col else col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaeb98cf-2b68-45fa-b8b4-76def30475e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_cols = ['cow', 'date', 'begin_time', 'days_in_milk', 'device_name', 'is_incomplete', 'interval_sec']\n",
    "col_dict = get_col_dict(visit_df, [\"lf\", \"lr\", \"rr\", \"rf\"])\n",
    "visit_long = merge_long(visit_df, info_cols, col_dict)\n",
    "# feature long format\n",
    "info_cols = [\"cow\"]\n",
    "col_dict = get_col_dict(feature_df, [\"lf\", \"lb\", \"rb\", \"rf\"])\n",
    "ft_long = merge_long(feature_df, info_cols, col_dict)\n",
    "ft_long[\"teat\"] = [t.replace(\"b\", \"r\") for t in ft_long.teat]\n",
    "\n",
    "merged_long = pd.merge(ft_long, visit_long, left_on = [\"cow\", \"teat\"], right_on = [\"cow\", \"teat\"])\n",
    "merged_long.to_csv(os.path.join(out_dir, \"visit_ft_long.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47a600d3-cbe8-4320-92b5-3d3783c21eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_cols = ['cow', 'date', 'begin_time', 'days_in_milk', 'device_name', 'is_incomplete', 'interval_sec']\n",
    "col_dict = ['yield', 'is_incomplete', 'occ']\n",
    "visit_long = visit_df[info_cols + col_dict]\n",
    "# feature long format\n",
    "info_cols = [\"cow\"]\n",
    "col_dict =  [col for col in feature_df.columns if col.split(\"_\")[-1] == \"udder\"]\n",
    "ft_long = feature_df[info_cols+col_dict]\n",
    "\n",
    "merged_long = pd.merge(ft_long, visit_long, left_on = [\"cow\"], right_on = [\"cow\"])\n",
    "merged_long.to_csv(os.path.join(out_dir, \"visit_ft_long_udder.csv\"), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
