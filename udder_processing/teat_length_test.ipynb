{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d08a838c-969e-4d76-b718-f2b2e95969fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json \n",
    "\n",
    "import open3d as o3d\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, Matern, Sum, CompoundKernel\n",
    "# import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57d73b70-6b0f-4985-8345-413a8c03ee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_sample(points):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    downpcd = pcd.voxel_down_sample(voxel_size=0.005)\n",
    "    return np.asarray(downpcd.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "892812c9-9e8d-4bc0-a7d0-f4486dd586b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list files \n",
    "dirpath = os.getcwd()\n",
    "pcd_path = os.path.join(dirpath, \"point_clouds\")\n",
    "udder_path = os.path.join(pcd_path, \"udder\")\n",
    "kp_path = os.path.join(pcd_path, \"keypoints\")\n",
    "quarter_path = os.path.join(pcd_path, \"quarters\")\n",
    "\n",
    "out_path = os.path.join(dirpath, \"features_dict\")\n",
    "\n",
    "filenames = [file.replace(\".json\", \"\") for file in os.listdir(kp_path)]\n",
    "kernel = 1.0 * RBF(length_scale=1.0, length_scale_bounds=(1e-5, 1e2))  + WhiteKernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1be4ecd-fc44-44eb-b19e-46d02a0a6c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marie\\miniconda3\\envs\\napari-env2\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning:\n",
      "\n",
      "The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "\n",
      "C:\\Users\\marie\\miniconda3\\envs\\napari-env2\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning:\n",
      "\n",
      "The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "\n",
      "C:\\Users\\marie\\miniconda3\\envs\\napari-env2\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning:\n",
      "\n",
      "The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "\n",
      "C:\\Users\\marie\\miniconda3\\envs\\napari-env2\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning:\n",
      "\n",
      "The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "skip_files = []\n",
    "cnt = 0\n",
    "for file in filenames:\n",
    "    print(cnt)\n",
    "    cnt+=1\n",
    "    udder_pc = np.load(os.path.join(udder_path, file + \".npy\"))\n",
    "    \n",
    "    with open(os.path.join(quarter_path, file + \".json\")) as f:\n",
    "        quarter_dict = json.load(f)\n",
    "    \n",
    "    with open(os.path.join(kp_path, file + \".json\")) as f:\n",
    "        kp_dict = json.load(f)\n",
    "        \n",
    "    pcd_dict = {}\n",
    "    teat_dict = {} \n",
    "    skip = 0\n",
    "    for key in quarter_dict.keys():\n",
    "        quarter = np.array(quarter_dict[key])\n",
    "        teat = np.array(kp_dict[key]['xyz_tf'])\n",
    "        dist_teat = np.array([np.linalg.norm(teat[:2]-point[:2]) for point in quarter])\n",
    "        max_dist_quarter = np.max(dist_teat)\n",
    "        \n",
    "        delta_z = []\n",
    "        radi = []\n",
    "        z_val = []\n",
    "        rad = 0.001\n",
    "        last_rad = 0\n",
    "        step = 0.002\n",
    "        last_z = teat[2]\n",
    "        \n",
    "        while rad < max_dist_quarter:\n",
    "            # sort the distances\n",
    "            # points within 1mm \n",
    "            condition = [(d <= rad) & (d > last_rad) for d in dist_teat]\n",
    "            if sum(condition) >0:\n",
    "                circle_idx = np.where(condition)[0]\n",
    "                cirle_dist = dist_teat[circle_idx]\n",
    "                circle_pts = quarter[circle_idx]\n",
    "                circle_z = np.min(circle_pts[:, 2])\n",
    "                \n",
    "                # max distance in circle\n",
    "                max_dist_circle = np.max(cirle_dist)\n",
    "                \n",
    "                # look at the z change\n",
    "                dif = abs(circle_z - last_z)\n",
    "                delta_z.append(dif)\n",
    "                radi.append(rad)\n",
    "                z_val.append(circle_z)\n",
    "                \n",
    "                # update stuff\n",
    "                last_rad = rad   \n",
    "                last_z = circle_z\n",
    "            rad += step \n",
    "        delta_z = np.array(delta_z)\n",
    "        radi = np.array(radi)\n",
    "        z_val = np.array(z_val)\n",
    "        \n",
    "        small_gradient = [(d >= 0) & (d < 0.001) for d in delta_z]\n",
    "        small_idx = np.where(small_gradient)[0]\n",
    "        candidates = np.array(radi[small_idx])\n",
    "        candidates_h = np.array(z_val[small_idx])\n",
    "        \n",
    "        try:\n",
    "            cand_idx = np.where((candidates[1:] - candidates[:-1]) > step*2)[0][0]\n",
    "            teat_radius = candidates[cand_idx+1] -step\n",
    "            teat_z = candidates_h[cand_idx+1]\n",
    "        except:\n",
    "            skip = 1\n",
    "            skip_files.append(file)\n",
    "    \n",
    "        if skip == 0:\n",
    "            # flag the points that are teat \n",
    "            base_idx = np.where(dist_teat < teat_radius)[0]\n",
    "            lowpts_idx = np.where(quarter[:, 2] < teat_z)[0]\n",
    "            base_coords = np.row_stack((quarter[base_idx], quarter[lowpts_idx]))\n",
    "            quarter2 = quarter.copy()\n",
    "            quarter2[base_idx, 2] = np.nan\n",
    "            quarter2[lowpts_idx, 2] = np.nan\n",
    "            \n",
    "            dspc = down_sample(quarter2)\n",
    "            \n",
    "            missing = dspc[np.isnan(dspc[:, 2]), :2]\n",
    "            observed = dspc[~np.isnan(dspc[:, 2]), :]\n",
    "            \n",
    "            gaussian_process = GaussianProcessRegressor(kernel=kernel)\n",
    "            gaussian_process.fit(observed[:,:2], observed[:,2])\n",
    "            vals = gaussian_process.predict(missing[:, :2], return_std=False)\n",
    "            predicted = np.column_stack([missing, np.transpose(vals)])\n",
    "            pcd_dict[key] = {\"teat_pts\": base_coords.tolist(), \"obs_pts\": observed.tolist(), \"pred_pts\": predicted.tolist()}\n",
    "            \n",
    "            leng_all = np.array([np.linalg.norm(teat - point) for point in predicted])\n",
    "            teat_base = predicted[np.argsort(leng_all)[0]]\n",
    "            teat_length = leng_all[np.argsort(leng_all)[0]]\n",
    "            \n",
    "            teat_dict[key] = {\"bottom\": teat.tolist(), \"tip\": teat_base.tolist(), \"length\": teat_length}\n",
    "        \n",
    "    with open(os.path.join(pcd_path, \"teat\", file + \".json\"), 'w') as f:\n",
    "        json.dump(pcd_dict, f)\n",
    "    with open(os.path.join(out_path, \"teat_length\", file + \".json\"), 'w') as f:\n",
    "        json.dump(teat_dict, f)\n",
    "\n",
    "print(skip_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2020753e-69dc-4f7c-811c-c50d77cd5b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lf': {'bottom': array([0.03796229, 0.07697083, 0.06092589]),\n",
       "  'tip': array([0.02624866, 0.08415521, 0.08539687]),\n",
       "  'length': 0.02806516226785275}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68b1501f-0489-4e38-aa32-a8ea711801d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stuff(observed, predicted, base_coords):\n",
    "    points = observed\n",
    "    x = points[:, 0]\n",
    "    y = points[:, 1]\n",
    "    z = points[:, 2]\n",
    "    fig =  go.Figure(data=[go.Scatter3d(x=x, y=y, z=z, mode='markers', marker=dict(color=\"slateblue\", size = 1, opacity = 0.5), name = \"Udder\")])\n",
    "    \n",
    "    points = predicted \n",
    "    x = points[:, 0]\n",
    "    y = points[:, 1]\n",
    "    z = points[:, 2]\n",
    "    fig.add_trace(go.Scatter3d(x=x, y=y, z=z, mode='markers', marker=dict(color=\"blue\", size = 2), name = \"ols\"))\n",
    "    \n",
    "    points = base_coords\n",
    "    x = points[:, 0]\n",
    "    y = points[:, 1]\n",
    "    z = points[:, 2]\n",
    "    fig.add_trace(go.Scatter3d(x=x, y=y, z=z, mode='markers', marker=dict(color=\"yellow\", size = 2), name = \"teat\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e92006-0027-474f-b595-d75ce757058e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
